{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90590a9a",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "e7c4cad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "01c696c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "Scissor resize done\n",
      "42  images to be resized.\n",
      "42  images resized.\n",
      "Rock resize done\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "Paper resize done\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "    print(len(images), \" images to be resized.\")\n",
    "\n",
    "    # file Resize 28x28 and save\n",
    "    target_size=(28,28)\n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "    \n",
    "    print(len(images), \" images resized.\")\n",
    "\n",
    "# load image and resize\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"Scissor resize done\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"Rock resize done\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"Paper resize done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "7a902c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train's image count 242\n",
      "x_train shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=300):\n",
    "    # scissor : 0, rock : 1, paper : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #create matrix image and label(scissor : 0, rock : 1, paper : 2)\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # copy image matrix into data area\n",
    "        labels[idx]=0   # scissor : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    \n",
    "        labels[idx]=1   # rock : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    \n",
    "        labels[idx]=2   # paper : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"x_train's image count\", idx)\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # nomalization input value 0~1\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "b15b3e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hello\n",
    "plt.imshow(x_train[0])\n",
    "print('label: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "32fdb334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_72 (Conv2D)           (None, 26, 26, 100)       2800      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_72 (MaxPooling (None, 13, 13, 100)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_73 (Conv2D)           (None, 11, 11, 32)        28832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_73 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_36 (Flatten)         (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 57,363\n",
      "Trainable params: 57,363\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 11.1074 - accuracy: 0.4600\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 2.4156 - accuracy: 0.5567\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.4649 - accuracy: 0.6233\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0727 - accuracy: 0.6133\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8705 - accuracy: 0.6333\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6447 - accuracy: 0.7233\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5702 - accuracy: 0.7900\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.8667\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.8700\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4798 - accuracy: 0.8367\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.8833\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.8800\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3870 - accuracy: 0.9100\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3617 - accuracy: 0.9200\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3131 - accuracy: 0.9433\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3259 - accuracy: 0.9333\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2759 - accuracy: 0.9567\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2755 - accuracy: 0.9433\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2869 - accuracy: 0.9500\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2703 - accuracy: 0.9533\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2632 - accuracy: 0.9500\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2353 - accuracy: 0.9667\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2222 - accuracy: 0.9633\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2212 - accuracy: 0.9600\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1968 - accuracy: 0.9733\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1908 - accuracy: 0.9667\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1824 - accuracy: 0.9700\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1829 - accuracy: 0.9667\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1856 - accuracy: 0.9600\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2232 - accuracy: 0.9367\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2129 - accuracy: 0.9533\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1723 - accuracy: 0.9633\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1438 - accuracy: 0.9733\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1328 - accuracy: 0.9800\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1340 - accuracy: 0.9800\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9733\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1238 - accuracy: 0.9833\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1084 - accuracy: 0.9833\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1154 - accuracy: 0.9800\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1304 - accuracy: 0.9733\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1086 - accuracy: 0.9833\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0962 - accuracy: 0.9833\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0928 - accuracy: 0.9867\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0863 - accuracy: 0.9867\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0857 - accuracy: 0.9867\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0866 - accuracy: 0.9833\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0712 - accuracy: 0.9867\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0701 - accuracy: 0.9867\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.9867\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9867\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0626 - accuracy: 0.9867\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9900\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 0.9900\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0625 - accuracy: 0.9867\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.9867\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0471 - accuracy: 0.9900\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 0.9900\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9900\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.9900\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9967\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.9900\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0363 - accuracy: 0.9933\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0344 - accuracy: 0.9933\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0376 - accuracy: 0.9967\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0367 - accuracy: 0.9933\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0324 - accuracy: 0.9967\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0348 - accuracy: 0.9967\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0319 - accuracy: 0.9967\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0312 - accuracy: 0.9900\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0265 - accuracy: 0.9967\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0252 - accuracy: 0.9967\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 0.9967\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0230 - accuracy: 0.9967\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0231 - accuracy: 0.9967\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0242 - accuracy: 0.9967\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0239 - accuracy: 0.9967\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0223 - accuracy: 0.9967\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0208 - accuracy: 0.9967\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 0.9967\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0246 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0209 - accuracy: 0.9967\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0189 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 0.9967\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9967\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 0.9967\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9967\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9967\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 0.9967\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.9967\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9967\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9967\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0105 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdab4070190>"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hyper parameter tunning\n",
    "n_channel_1=100\n",
    "n_channel_2=32\n",
    "n_dense=32\n",
    "n_train_epoch=100\n",
    "\n",
    "#make model\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "bb920944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Reshape - x_train_norm shape: (300, 28, 28, 3)\n",
      "Before Reshape - y_train_norm shape: (300,)\n",
      "After Reshape - x_train_reshaped shape: (300, 28, 28, 3)\n",
      "After Reshape - y_train_reshaped shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "\n",
    "print(\"Before Reshape - x_train_norm shape: {}\".format(x_train.shape))\n",
    "print(\"Before Reshape - y_train_norm shape: {}\".format(y_train.shape))\n",
    "\n",
    "x_train_reshaped=x_train.reshape( -1, 28, 28, 3)  # -1 : auto-calculate data count\n",
    "y_train_reshaped=y_train.reshape( -1,)\n",
    "\n",
    "print(\"After Reshape - x_train_reshaped shape: {}\".format(x_train_reshaped.shape))\n",
    "print(\"After Reshape - y_train_reshaped shape: {}\".format(y_train_reshaped.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "bcd0eba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "Scissor resize done\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "Paper resize done\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "Rock resize done\n",
      "x_train's image count 300\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "#make x_test, y_test\n",
    "#/test/\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"Scissor resize done\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"Paper resize done\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"Rock resize done\")\n",
    "\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # nomalization input value 0~1\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "2438ffba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.8878 - accuracy: 0.7367\n",
      "test_loss: 0.8877754807472229 \n",
      "test_accuracy: 0.7366666793823242\n"
     ]
    }
   ],
   "source": [
    "#test accuracy\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67f1695",
   "metadata": {},
   "source": [
    "### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5907858",
   "metadata": {},
   "source": [
    "#### Conclusion \n",
    "\n",
    "1. The test accuacy does not rise by increasing the hyperparameters. 10,000 epochs were also tried, but there was no effect on accuracy.\n",
    "2. It is necessary not only to design a model, but also to think about how to mathematically tune the model. Then, study of relu, softmax, and adam should be preceded first.\n",
    "3. During the group discussion, we continued to search for hyperparameter tuning and kerastuner. When the test set was constructed with rock-paper-scissors photos taken by other people, the test acuity was up to 0.50 was shown.\n",
    "In particular, 0.33 came out frequently at first, but the accuracy of 0.33 in rock-paper-scissors means that my model is not predicting at all.\n",
    "\n",
    "This is my conclusion after much consideration.\n",
    "I think it is difficult to accurately predict different backgrounds and other people's hands in a situation where the train set is only 100 for each case.\n",
    "That is, I think tuning was difficult due to a lack of absolute train data numbers, not a problem of model tuning.\n",
    "\n",
    "Even though I made new test data set with the same hand in the same background, the accuracy was around 0.73.\n",
    "So when someone else makes test data against a different background, it seems difficult to exceed the accuracy of 0.60.\n",
    "In the first place, it is difficult to learn high-performance because there are only 100 pictures of each rock-scissor-paper case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
